\frame{
\frametitle{TAEN: Tikhonov Autoencoder Network}
\vspace{-2ex}

{\small

\begin{corollary}
Given \myblue{\bf $\bar{Y}$ is a full row rank} training data, for a test observation sample $\ybtest$, the predicted \texttt{TAEN} inverse solution is
\begin{equation*}
    \ub^{\TNetAE} = \Psie^*(\ybtest) = \LRp{ \Ib + \lambda {\GB}^T \GB }^{-1} \LRp{ \ub_0 + \lambda {\GB}^T \ybtest}
\end{equation*}
which is exactly the inverse solution of the following linear Tikhonov regularization problem
\begin{equation*}
    \min_{\ub}  \halfv{1} \nor{\ub - \ub_0}_{2}^2 + \halfv{\lambda} \nor{\GB \ub - \ybtest}_{2}^2.
\end{equation*}
Then, the \myred{test inverse solution error}
\[
    \epsb_{\ubtest}^{\TNetAE} = \nor{\Psie^*(\ybtest) - \ubtest }_2^2 \leq  \nor{{\ub^\text{test} - {\ub}_0} }_2^2
\]        
Meanwhile, for a test parameter $\ubtest$, the \myred{test forward solution error}
\[
    \epsb_{\ybtest}^{\TNetAE} = \nor{\Psid^*(\ubtest) - \ybtest }_2^2  = 0,
\]
\end{corollary}
}
}